{"cells":[{"cell_type":"markdown","metadata":{},"source":["Laboratorio 5 rederes neuronales\n","Diego Roberto Arancibia Delgado\n","Aplicar el codigo de redes neuronales en clase y comentar los resultados obtenidos, ademas de las mejores configuraciones de parametros e hiperparametros optimos.\n","link del repositorio: \n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1714052334171,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"stUHtyXwtUTc"},"outputs":[],"source":["# used for manipulating directory paths\n","import os\n","\n","# Scientific and vector computation for python\n","import numpy as np\n","\n","# Plotting library\n","from matplotlib import pyplot\n","\n","# Optimization module in scipy\n","from scipy import optimize\n","\n","import numpy as np\n","\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","\n","# will be used to load MATLAB mat datafile format\n","# from scipy.io import loadmat\n","\n","# library written for this exercise providing additional functions for assignment submission, and others\n","# import utils\n","\n","from matplotlib import pyplot\n","\n","# Modulo de optimizacion en scipy\n","from scipy import optimize\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","import tabulate\n","\n","# tells matplotlib to embed plots within the notebook\n","%matplotlib inline"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37137,"status":"ok","timestamp":1714052371306,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"qCQdjXpNtha3","outputId":"6d4418b5-7154-47df-cbdd-05e57253256e"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":657,"status":"ok","timestamp":1714053824835,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"iPKROwkOtpkn","outputId":"8b94cac3-551c-4842-a894-8b9d26038638"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>pixel9</th>\n","      <th>...</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","      <th>pixel784</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30</td>\n","      <td>43</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>59995</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>59996</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>73</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>59997</th>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>160</td>\n","      <td>162</td>\n","      <td>163</td>\n","      <td>135</td>\n","      <td>94</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>59998</th>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>59999</th>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>60000 rows × 785 columns</p>\n","</div>"],"text/plain":["       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n","0          2       0       0       0       0       0       0       0       0   \n","1          9       0       0       0       0       0       0       0       0   \n","2          6       0       0       0       0       0       0       0       5   \n","3          0       0       0       0       1       2       0       0       0   \n","4          3       0       0       0       0       0       0       0       0   \n","...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n","59995      9       0       0       0       0       0       0       0       0   \n","59996      1       0       0       0       0       0       0       0       0   \n","59997      8       0       0       0       0       0       0       0       0   \n","59998      8       0       0       0       0       0       0       0       0   \n","59999      7       0       0       0       0       0       0       0       0   \n","\n","       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n","0           0  ...         0         0         0         0         0   \n","1           0  ...         0         0         0         0         0   \n","2           0  ...         0         0         0        30        43   \n","3           0  ...         3         0         0         0         0   \n","4           0  ...         0         0         0         0         0   \n","...       ...  ...       ...       ...       ...       ...       ...   \n","59995       0  ...         0         0         0         0         0   \n","59996       0  ...        73         0         0         0         0   \n","59997       0  ...       160       162       163       135        94   \n","59998       0  ...         0         0         0         0         0   \n","59999       0  ...         0         0         0         0         0   \n","\n","       pixel780  pixel781  pixel782  pixel783  pixel784  \n","0             0         0         0         0         0  \n","1             0         0         0         0         0  \n","2             0         0         0         0         0  \n","3             1         0         0         0         0  \n","4             0         0         0         0         0  \n","...         ...       ...       ...       ...       ...  \n","59995         0         0         0         0         0  \n","59996         0         0         0         0         0  \n","59997         0         0         0         0         0  \n","59998         0         0         0         0         0  \n","59999         0         0         0         0         0  \n","\n","[60000 rows x 785 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# datos de entrenamiento almacenados en los arreglos X, y\n","data = pd.read_csv(\"fashion-mnist_train.csv\", delimiter=',')\n","\n","data"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 60000 entries, 0 to 59999\n","Columns: 785 entries, label to pixel784\n","dtypes: int64(785)\n","memory usage: 359.3 MB\n"]}],"source":["data.info()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["data_mezclado = shuffle(data, random_state=None)\n","train_df, test_df = train_test_split(data_mezclado, test_size=0.2, random_state=None)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["((48000, 785), (12000, 785))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape, test_df.shape"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["y_train = train_df['label']\n","x_train = train_df.iloc[:, 1:]\n","\n","y_test = test_df['label']\n","x_test = test_df.iloc[:, 1:]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["((48000, 784), (48000,), (12000, 784), (12000,))"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["48000\n"]}],"source":["value_counts = y_train.shape[0]\n","\n","print(value_counts)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"YN2IfP_5vz8v","outputId":"ed1b63c6-ce2a-47d0-982b-7e49c74d776d"},"outputs":[{"name":"stdout","output_type":"stream","text":["(615440,)\n","(7850,)\n","(623290,)\n"]}],"source":["# Configurando parametros necesario\n","input_layer_size  = 784 #20x20 Imagenes de dígitos de entrada\n","hidden_layer_size = 784 # unidades ocultas\n","num_labels = 10          # 10 etiquetas, de 0 a 9\n","\n","# carga los pesos en las variables Theta1 y Theta2\n","# weights = loadmat(os.path.join('/content/gdrive/MyDrive/Colab Notebooks/machine learning/data', 'ex4weights.mat'))\n","# weights = np.array()\n","pesos = {}\n","pesos['Theta1'] = np.random.rand(hidden_layer_size, input_layer_size+1)  # 784 características + 1 para el sesgo\n","pesos['Theta2'] = np.random.rand(num_labels, hidden_layer_size+1)  # 10 clases, 10 nodos en la capa oculta + 1 para el sesgo\n","# print(pesos['Theta1'][:].shape)\n","# print(pesos['Theta2'][:].shape)\n","\n","# print(weights['Theta1'][:].shape)\n","# print(weights['Theta2'][:].shape)\n","\n","# print(weights['Theta1'][0])\n","# print(np.roll(weights['Theta1'][0], 1, axis=0))\n","# Theta1 tiene un tamaño de 25x401\n","# Theta2 tiene un tamañó de 10x26\n","# Theta1, Theta2 = weights['Theta1'], weights['Theta2']\n","Theta1, Theta2 = pesos['Theta1'], pesos['Theta2']\n","# se intercambia la ultima columa con la primera de Theta2, por cuestiones de indices que utiliza MATLAB\n","# print(Theta2)\n","# print(np.roll(Theta2, 1, axis=0))\n","\n","# Theta2 = np.roll(Theta2, 1, axis=0)\n","\n","# Desenrollar parámetros\n","print(Theta1.ravel().shape)\n","print(Theta2.ravel().shape)\n","\n","nn_params = np.concatenate([Theta1.ravel(), Theta2.ravel()])\n","print(nn_params.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"IYkAveQh0e87"},"outputs":[],"source":["def sigmoid(z):\n","    # Limita el rango de z para evitar desbordamientos\n","    z = np.clip(z, -500, 500)\n","    return 1.0 / (1.0 + np.exp(-z))\n","\n","\n","def sigmoidGradient(z):\n","\n","    g = np.zeros(z.shape)\n","\n","    g = sigmoid(z) * (1 - sigmoid(z))\n","\n","    return g"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Aevzq-rt0vKn"},"outputs":[],"source":["def nnCostFunction(nn_params,\n","                   input_layer_size,\n","                   hidden_layer_size,\n","                   num_labels,\n","                   X, y, lambda_):\n","    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n","    # for our 2 layer neural network\n","    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n","                        (hidden_layer_size, (input_layer_size + 1)))\n","\n","    Theta2_size = num_labels * (hidden_layer_size + 1)\n","    Theta2 = np.reshape(nn_params[-Theta2_size:],\n","                        (num_labels, (hidden_layer_size + 1)))\n","\n","    m = y.size\n","    J = 0\n","    Theta1_grad = np.zeros(Theta1.shape)\n","    Theta2_grad = np.zeros(Theta2.shape)\n","\n","    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n","\n","    a2 = sigmoid(a1.dot(Theta1.T))\n","    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n","\n","    a3 = sigmoid(a2.dot(Theta2.T))\n","\n","    # print(\"-\"*20)\n","    # print(y.shape)\n","    # print(y.reshape(-1))\n","    # print(\"-\"*20)\n","    y_matrix = y.reshape(-1)\n","    # print(y.shape)\n","    y_matrix = np.eye(num_labels)[y_matrix]\n","    # print(y_matrix)\n","\n","    temp1 = Theta1\n","    temp2 = Theta2\n","\n","    # Agregar el termino de regularización\n","\n","    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])))\n","\n","    epsilon = 1e-5  # Una pequeña constante\n","    J = (-1 / m) * np.sum((np.log(a3 + epsilon) * y_matrix) + np.log(1 - a3 + epsilon) * (1 - y_matrix)) + reg_term\n","\n","    # Backpropogation\n","\n","    delta_3 = a3 - y_matrix\n","    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n","\n","    Delta1 = delta_2.T.dot(a1)\n","    Delta2 = delta_3.T.dot(a2)\n","\n","    # Agregar regularización al gradiente\n","\n","    Theta1_grad = (1 / m) * Delta1\n","    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n","\n","    Theta2_grad = (1 / m) * Delta2\n","    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n","\n","    # ===================== Alterntate solutions =====================\n","    # my_final_matrix = np.zeros(a3.shape)\n","    # for c in np.arange(num_labels):\n","    #    my_final_matrix[:, c] = (np.log(a3[:, c]) * (y == c)) + (np.log(1 - a3[:, c]) * (1 - (y == c)))\n","    #J = (-1 / m) * np.sum(my_final_matrix)\n","    # ================================================================\n","\n","    # ================================================================\n","    # Unroll gradients\n","    # grad = np.concatenate([Theta1_grad.ravel(order=order), Theta2_grad.ravel(order=order)])\n","\n","    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n","\n","    return J, grad"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"k4TjzE2h3BqL","outputId":"4cc70294-8e0a-4454-8ee2-d5da822b7686"},"outputs":[{"name":"stdout","output_type":"stream","text":["Costo en parametros (cargado de ex4weights): 103.616319 \n","El costo debe esta cercano a               : 0.287629\n"]}],"source":["lambda_ = 0\n","J, _ = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, x_train.values, y_train.values, lambda_)\n","print('Costo en parametros (cargado de ex4weights): %.6f ' % J)\n","print('El costo debe esta cercano a               : 0.287629')"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"cT80ttRF-Rdv","outputId":"b889f53d-51c0-41d9-e0ff-72f6e2c41b51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Gradiente sigmoide evaluada con [-1 -0.5 0 0.5 1]:\n","  \n","[0.19661193 0.23500371 0.25       0.23500371 0.19661193]\n"]}],"source":["z = np.array([-1, -0.5, 0, 0.5, 1])\n","g = sigmoidGradient(z)\n","print('Gradiente sigmoide evaluada con [-1 -0.5 0 0.5 1]:\\n  ')\n","print(g)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"EnKgJRZq-x3U"},"outputs":[],"source":["def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n","    \"\"\"\n","    Randomly initialize the weights of a layer in a neural network.\n","\n","    Parameters\n","    ----------\n","    L_in : int\n","        Number of incomming connections.\n","\n","    L_out : int\n","        Number of outgoing connections.\n","\n","    epsilon_init : float, optional\n","        Range of values which the weight can take from a uniform\n","        distribution.\n","\n","    Returns\n","    -------\n","    W : array_like\n","        The weight initialiatized to random values.  Note that W should\n","        be set to a matrix of size(L_out, 1 + L_in) as\n","        the first column of W handles the \"bias\" terms.\"\"\"\n","\n","\n","    W = np.zeros((L_out, 1 + L_in))\n","    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n","\n","    return W"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"znk_8rO0-6fE","outputId":"9b9a683b-1174-4635-e633-f26c03d371ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Inicialización de parámetros de redes neuronales...\n"]}],"source":["print('Inicialización de parámetros de redes neuronales...')\n","\n","initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n","initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n","\n","# Desenrrollr parametros\n","initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"-ysYL_hX_D0k","outputId":"a0ae7984-4221-4297-c093-bbd6bdecef90"},"outputs":[],"source":["#  After you have completed the assignment, change the maxiter to a larger\n","#  value to see how more training helps.\n","options= {'maxiter': 100}\n","\n","#  You should also try different values of lambda\n","lambda_ = 1\n","\n","# Create \"short hand\" for the cost function to be minimized\n","costFunction = lambda p: nnCostFunction(p, input_layer_size,\n","                                        hidden_layer_size,\n","                                        num_labels, x_train.values, y_train.values, lambda_)\n","\n","# Now, costFunction is a function that takes in only one argument\n","# (the neural network parameters)\n","res = optimize.minimize(costFunction,\n","                        initial_nn_params,\n","                        jac=True,\n","                        method='CG',  # Cambia 'BFGS' a 'CG'\n","                        options=options)\n","\n","# get the solution of the optimization\n","nn_params = res.x\n","\n","# Obtain Theta1 and Theta2 back from nn_params\n","Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n","                    (hidden_layer_size, (input_layer_size + 1)))\n","\n","Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n","                    (num_labels, (hidden_layer_size + 1)))"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"XDnQrQM4_0Ct"},"outputs":[],"source":["def predict(Theta1, Theta2, X):\n","    \"\"\"\n","    Predict the label of an input given a trained neural network\n","    Outputs the predicted label of X given the trained weights of a neural\n","    network(Theta1, Theta2)\n","    \"\"\"\n","    # Useful values\n","    m = X.shape[0]\n","    num_labels = Theta2.shape[0]\n","\n","    # You need to return the following variables correctly\n","    p = np.zeros(m)\n","    h1 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), X], axis=1), Theta1.T))\n","    h2 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), h1], axis=1), Theta2.T))\n","    p = np.argmax(h2, axis=1)\n","    return p"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"rxMinI1Y_6AG","outputId":"1a129f5b-574a-468a-eae5-dee890bd06e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[3 3 9 ... 1 3 3]\n","Training Set Accuracy: 86.850000\n"]}],"source":["pred = predict(Theta1, Theta2, x_train.values[:,:])\n","print(pred)\n","print('Training Set Accuracy: %f' % (np.mean(pred == y_train.values[:]) * 100))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1714052374183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"1Qrmea3i_hip","outputId":"aeae320f-f8da-4288-8e9e-f7e9ad65133a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 4 4 ... 8 2 4]\n","Training Set Accuracy: 83.941667\n"]}],"source":["pred = predict(Theta1, Theta2, x_test.values[:,:])\n","print(pred)\n","print('Training Set Accuracy: %f' % (np.mean(pred == y_test.values[:]) * 100))\n"]},{"cell_type":"markdown","metadata":{},"source":["el indice de prediccion es mas del 50 y ademas casi llega a un 90 lo que dice que la red neuronal es buena pero por limitaciones y que el dtaset era de un tamaño considerable se añadio una pequeña constante a a3 y 1 - a3 para evitar tomar el logaritmo de cero utilizando epsilon para asegurarse de que a3 y 1 - a3 sean al menos epsilon este es la parte que se cambio\n","epsilon = 1e-5  # Una pequeña constante\n","J = (-1 / m) * np.sum((np.log(a3 + epsilon) * y_matrix) + np.log(1 - a3 + epsilon) * (1 - y_matrix)) + reg_term.\n","ademas se uso envez de numpy la libreria de sklearn para la separacion de datos, el reslto de codigo se saco del cuadernillo de redes neuronales vinos\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOnY6s1mk+XoVNHHBXQBN/G","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
